# ===========================================================
# ğŸš€ Nifty 50 Trading System - Makefile
# ===========================================================
#
# Quick Reference:
#   make up          - Start full stack (Infra + App + UI + Notify)
#   make down        - Stop everything (with Auto-Backup)
#   make dev-nodb    - Restart apps only (Keep DB/Kafka running)
#   make logs        - Tail all container logs
#   make help        - Show all commands
#
# ===========================================================

.PHONY: help up down infra wait-kafka app ui observe logs clean backup restore

COMPOSE_DIR := infrastructure/compose
DC := docker-compose --env-file .env

# ===========================================================
# 1. HELP
# ===========================================================

help:
	@echo "ğŸš€ Nifty 50 Trading System"
	@echo ""
	@echo "ğŸ“¦ LIFECYCLE (Docker)"
	@echo "  make up             Start full stack"
	@echo "  make down           Stop everything (Auto-Backup)"
	@echo "  make dev-nodb       Restart Apps (Keep DB/Kafka running)"
	@echo "  make stop-all       Force Stop (Skip Backup)"
	@echo ""
	@echo "ğŸ§© COMPONENTS"
	@echo "  make infra          Start Data Layer (Kafka, Redis, DB)"
	@echo "  make app            Start Pipeline (L1-L6 + API)"
	@echo "  make ui             Start Dashboard"
	@echo "  make notify         Start Telegram Bot & Email"
	@echo "  make observe        Start Monitoring (Grafana + Prom)"
	@echo ""
	@echo "ğŸ“¦ DATABASE & CACHE"
	@echo "  make backup         Backup TimescaleDB to ./backups/"
	@echo "  make restore        Restore from latest backup"
	@echo "  make check-restore  Verify database content"
	@echo "  make check-version  Check TimescaleDB version compatibility"
	@echo "  make db-reset       Full database reset (schema + data)"
	@echo "  make clear-data     Clear candles_1m & data_availability tables"
	@echo "  make redis-clear    Flush all Redis cache"
	@echo ""
	@echo "ğŸ’» LOCAL DEV"
	@echo "  make layer[1-7]     Run specific layer locally (npm/go)"
	@echo "  make dev            Start infrastructure for local dev"
	@echo ""
	@echo "ğŸ§¹ MAINTENANCE"
	@echo "  make logs           Tail logs"
	@echo "  make clean          Remove build artifacts"
	@echo "  make fix-kafka      Fix Kafka Cluster ID issues"
	@echo "  make restart-ingestion  Rebuild & restart ingestion with .env"
	@echo ""

# ===========================================================
# 2. LIFECYCLE MANAGEMENT
# ===========================================================

up: infra wait-kafka observe notify app ui check-restore
	@echo "ğŸš€ Full stack running!"
	@echo ""
	@echo "ğŸŒ Frontend:"
	@echo "   - Dashboard:       http://localhost:3000"
	@echo "   - Gateway:         http://localhost:8088"
	@echo ""
	@echo "ğŸ”Œ APIs & Services:"
	@echo "   - Backend API:     http://localhost:4000"
	@echo "   - AI Service:      http://localhost:8000"
	@echo "   - Email Service:   http://localhost:7001"
	@echo "   - Telegram Bot:    http://localhost:7000"
	@echo ""
	@echo "ğŸ“Š Observability:"
	@echo "   - Grafana:         http://localhost:3001"
	@echo "   - Prometheus:      http://localhost:9090"
	@echo "   - Loki:            http://localhost:3100"
	@echo ""
	@echo "ğŸ”§ Infrastructure:"
	@echo "   (Run 'make infra' to see DB/Kafka details)"

down: backup
	@echo "ğŸ›‘ Stopping all containers..."
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.gateway.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.notify.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.ui.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.observe.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml down
	@echo "ğŸ—‘ï¸ Cleaning data folder..."
	@rm -rf data/*
	@echo "âœ… Stopped and cleaned."

dev-nodb:
	@echo "ğŸ”„ Restarting Applications (Keeping DB/Kafka running)..."
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.gateway.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.notify.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.ui.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml down
	@echo "âœ… Applications stopped."
	@make app ui notify
	@echo "ğŸš€ Applications restarted!"

stop-all:
	@echo "ğŸ›‘ FORCE Stopping all containers (Skipping Backup)..."
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.gateway.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.notify.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.ui.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.observe.yml down
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml down
	@echo "âœ… Stopped."

# ===========================================================
# 3. COMPONENT MANAGEMENT
# ===========================================================

# Version check for cross-machine compatibility
version-check:
	@echo "ğŸ” Checking data version compatibility..."
	@if [ -f data/.version ]; then \
		EXPECTED_VERSION=$$(grep TIMESCALEDB_VERSION data/.version | cut -d= -f2); \
		CONTAINER_VERSION=$$(docker run --rm timescale/timescaledb:2.24.0-pg15 psql --version 2>/dev/null | head -1 || echo "2.24.0"); \
		echo "   Data expects: TimescaleDB $$EXPECTED_VERSION"; \
		echo "   Container has: TimescaleDB 2.24.0"; \
		if [ "$$EXPECTED_VERSION" != "2.24.0" ]; then \
			echo "âš ï¸  VERSION MISMATCH! Data was created with $$EXPECTED_VERSION"; \
			echo "   Options:"; \
			echo "   1. Run 'make db-reset' to reset database (data loss!)"; \
			echo "   2. Update docker-compose.infra.yml to use version $$EXPECTED_VERSION"; \
			exit 1; \
		fi; \
	else \
		echo "   No version file found (first run or legacy data)"; \
	fi
	@echo "âœ… Version check passed!"

infra: version-check
	@echo "ğŸ”§ Starting Infrastructure..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml up -d --build
	@echo "â³ Waiting for TimescaleDB to be ready..."
	@sleep 3
	@echo "ğŸ“ Recording TimescaleDB version..."
	@-docker exec timescaledb psql -U trading -d nifty50 -t -c \
		"SELECT installed_version FROM pg_available_extensions WHERE name = 'timescaledb';" 2>/dev/null | \
		tr -d '[:space:]' > data/.tsdb_version 2>/dev/null || true
	@echo "LAST_MACHINE=$$(hostname)" >> data/.version 2>/dev/null || true
	@echo "âœ… Infrastructure Running:"
	@echo "   - Kafka:           9092"
	@echo "   - Kafka UI:        http://localhost:8090"
	@echo "   - Redis:           6379"
	@echo "   - Redis Commander: http://localhost:8085"
	@echo "   - TimescaleDB:     5432 (v$$(cat data/timescaledb/.tsdb_version 2>/dev/null || echo 'unknown'))"
	@echo "   - PgAdmin:         http://localhost:5051"

wait-kafka:
	@echo "â³ Waiting for Kafka to be healthy..."
	@MAX_RETRIES=20; \
	COUNTER=0; \
	until docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092 >/dev/null 2>&1; do \
		COUNTER=$$((COUNTER + 1)); \
		if [ $$COUNTER -ge $$MAX_RETRIES ]; then \
			echo "âŒ Kafka failed to become healthy after $$MAX_RETRIES attempts."; \
			echo "ğŸ’¡ Tip: Run 'make fix-kafka' to resolve ClusterID inconsistency errors."; \
			exit 1; \
		fi; \
		echo "   Kafka not ready yet ($$COUNTER/$$MAX_RETRIES), waiting..."; \
		sleep 3; \
	done
	@echo "âœ… Kafka is healthy!"

app:
	@echo "ğŸš€ Starting Pipeline (L1-L6 + API)..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml up -d --build
	@echo "âœ… Pipeline running."

app-build:
	@echo "ğŸš€ Rebuilding Pipeline..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml up -d --build
	@echo "âœ… Pipeline rebuilt."

ui:
	@echo "ğŸ–¥ï¸  Building Dashboard..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.ui.yml up -d --build
	@echo "âœ… http://localhost:3000"

notify:
	@echo "ï¿½ Starting Notifications..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.notify.yml up -d --build
	@echo "âœ… Telegram Bot & Email Service running"

notify-build:
	@echo "ğŸ”” Rebuilding Notifications..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.notify.yml up -d --build
	echo "âœ… Rebuilt Telegram Bot & Email Service"

observe:
	@echo "ğŸ“Š Starting Observability..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.observe.yml up -d --build
	@echo "âœ… Prometheus: 9090 | Grafana: 3001"

gateway:
	@echo "ğŸŒ Starting Gateway..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.gateway.yml up -d --build
	@echo "âœ… Gateway: http://localhost:8088"

ai:
	@echo "ğŸ§  Starting AI Stack (Inference + Ollama)..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml up -d ai-inference ollama
	@echo "âœ… AI Services running."

ai-restart:
	@echo "ğŸ”„ Restarting AI Stack..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml restart ai-inference ollama
	@echo "âœ… AI Services restarted."

ai-logs:
	@$(DC) -f $(COMPOSE_DIR)/docker-compose.app.yml logs -f ai-inference ollama

# ===========================================================
# 4. DATABASE OPERATIONS
# ===========================================================

backup:
	@echo "ğŸ’¾ Backing up TimescaleDB..."
	@if ! docker ps | grep -q timescaledb; then \
		echo "âš ï¸  TimescaleDB not running. Skipping backup."; \
	else \
		rm -rf backups/*; \
		TS=$$(date "+%d-%b-%Y_%I-%M-%S_%p"); \
		DIR="backups/Stock_Market_Live_Data_$$TS"; \
		mkdir -p $$DIR; \
		FILE=$$DIR/Stock_Market_Live_Data.sql; \
		echo "ğŸ“¦ Saving to $$DIR..."; \
		if docker exec timescaledb pg_dump -U trading nifty50 > $$FILE; then \
			echo "âœ… Backup saved: $$FILE"; \
		else \
			echo "âš ï¸  Backup failed."; \
			rm -rf $$DIR; \
		fi; \
	fi


backup-data:
	@echo "ğŸ§¹ Cleaning up old backups..."
	@rm -rf backups/*
	@TS=$$(date "+%d-%b-%Y_%I-%M-%S_%p"); \
	DIR="backups/Stock_Market_Live_Data_DataOnly_$$TS"; \
	mkdir -p $$DIR; \
	FILE=$$DIR/Stock_Market_Live_Data_DataOnly.sql; \
	echo "ğŸ’¾ Backing up TimescaleDB DATA ONLY to $$DIR..."; \
	if docker exec timescaledb pg_dump -U trading nifty50 --data-only > $$FILE; then \
		echo "âœ… Data-only backup saved: $$FILE"; \
	else \
		echo "âŒ Backup failed! Removing empty directory..."; \
		rm -rf $$DIR; \
		exit 1; \
	fi

backup-schema:
	@echo "ğŸ§¹ Cleaning up old backups..."
	@rm -rf backups/*
	@TS=$$(date "+%d-%b-%Y_%I-%M-%S_%p"); \
	DIR="backups/Stock_Market_Live_Data_SchemaOnly_$$TS"; \
	mkdir -p $$DIR; \
	FILE=$$DIR/Stock_Market_Live_Data_SchemaOnly.sql; \
	echo "ğŸ’¾ Backing up TimescaleDB SCHEMA ONLY to $$DIR..."; \
	if docker exec timescaledb pg_dump -U trading nifty50 --schema-only > $$FILE; then \
		echo "âœ… Schema-only backup saved: $$FILE"; \
	else \
		echo "âŒ Backup failed! Removing empty directory..."; \
		rm -rf $$DIR; \
		exit 1; \
	fi

# Reset database for version mismatch recovery
db-reset:
	@echo "âš ï¸  DATABASE RESET - This will DELETE all TimescaleDB data!"
	@read -p "Are you sure? Type 'yes' to confirm: " confirm && { [ "$$confirm" = "yes" ] || [ "$$confirm" = "y" ]; } || exit 1
	@echo "ğŸ›‘ Stopping TimescaleDB..."
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml stop timescaledb
	@echo "ğŸ—‘ï¸  Deleting data directory..."
	rm -rf data/timescaledb/*
	@echo "ğŸš€ Starting fresh TimescaleDB..."
	$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml up -d timescaledb
	@sleep 10
	@echo "ğŸ“¦ Running migrations..."
	@cd layer-3-storage/timescaledb/migrations && \
		for f in *.sql; do \
			echo "  Running $$f..."; \
			docker exec -i timescaledb psql -U trading -d nifty50 < "$$f"; \
		done
	@echo "ğŸ“ Creating version file..."
	@echo "TIMESCALEDB_VERSION=2.24.0" > data/.version
	@echo "POSTGRESQL_VERSION=15" >> data/.version
	@echo "SCHEMA_VERSION=004" >> data/.version
	@echo "CREATED_AT=$$(date +%Y-%m-%d)" >> data/.version
	@echo "LAST_MACHINE=$$(hostname)" >> data/.version
	@echo "âœ… Database reset complete!"
	@echo "ğŸ’¡ Run 'make up' to start the full system."

redis-clear:
	@echo "ğŸ—‘ï¸ Clearing Redis cache..."
	@docker exec redis redis-cli FLUSHALL
	@echo "âœ… Redis cache cleared!"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# clear-data: Clear market data tables (keeps schema intact)
# Use this when you want to re-import data without full db-reset
# Tables cleared: candles_1m, data_availability
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
clear-data:
	@echo "ğŸ—‘ï¸ Clearing market data tables..."
	@docker exec timescaledb psql -U trading -d nifty50 -c "TRUNCATE candles_1m CASCADE;"
	@docker exec timescaledb psql -U trading -d nifty50 -c "TRUNCATE data_availability;"
	@echo "ğŸ—‘ï¸ Clearing Redis cache..."
	@docker exec redis redis-cli FLUSHALL
	@echo "âœ… Data cleared! Tables: candles_1m, data_availability + Redis cache"

restore:
	@echo "ğŸ“‚ Available backups:"
	@find backups -name "*.sql" -maxdepth 2 | sort -r | head -10 || echo "No backups found!"
	@echo ""
	@read -p "Enter backup filepath (or press Enter for latest): " file; \
	if [ -z "$$file" ]; then \
		file=$$(find backups -name "*.sql" -maxdepth 2 | sort -r | head -1); \
	fi; \
	if [ -z "$$file" ]; then \
		echo "âŒ No backup file found!"; exit 1; \
	fi; \
	echo "âš ï¸  WARNING: This will overwite the current database with contents of $$file"; \
	read -p "Are you sure? Type 'y' or 'yes' to confirm: " confirm; \
	if [ "$$confirm" != "y" ] && [ "$$confirm" != "yes" ]; then \
		echo "âŒ Restore cancelled."; exit 1; \
	fi; \
	echo "ğŸ”„ Restoring from $$file..."; \
	docker exec -i timescaledb psql -U trading nifty50 < $$file; \
	echo "âœ… Restore complete!"

check-restore:
	@echo "ğŸ” Checking if database is empty..."
	@if ! docker exec timescaledb psql -U trading nifty50 -c "SELECT 1 FROM instruments LIMIT 1;" >/dev/null 2>&1; then \
		echo "âš ï¸  Database appears empty!"; \
		echo "ğŸ’¡ You can restore data using: make restore"; \
		echo "   Or run: make batch (to fetch fresh data)"; \
	else \
		COUNT=$$(docker exec timescaledb psql -U trading nifty50 -t -c "SELECT count(*) FROM instruments;" | tr -d '[:space:]'); \
		echo "âœ… Database contains $$COUNT rows in instruments."; \
	fi

version-check-manual:
	@echo "ğŸ” Checking TimescaleDB version compatibility..."
	@if [ -f data/.version ]; then \
		cat data/.version; \
	else \
		echo "âš ï¸  No version file found"; \
	fi

# ===========================================================
# 5. DATA & TESTING
# ===========================================================

batch:
	@echo "ğŸ“Š Fetching historical data..."
	cd layer-1-ingestion && node scripts/batch_nifty50.js

batch-symbol:
	cd layer-1-ingestion && node scripts/batch_nifty50.js --symbol $(SYMBOL)

feed:
	@echo "ğŸ“¡ Feeding data to Kafka..."
	cd layer-1-ingestion && node scripts/feed_kafka.js

# Trigger backfill via Backend API (service must be running)
# Usage: make backfill [SYMBOL=RELIANCE] [FROM=2024-01-01] [TO=2024-12-31]
backfill:
	@echo "ğŸ“¡ Triggering Backfill via Backend API..."
	@curl -s -X POST http://localhost:4000/api/v1/system/backfill/trigger \
		-H "Content-Type: application/json" \
		-d '{"symbol":"$(SYMBOL)","fromDate":"$(FROM)","toDate":"$(TO)"}' | jq .
	@echo "âœ… Backfill job queued. Check status with: make backfill-status"

# View data availability status via Backend API
data-status:
	@echo "ğŸ“Š Data Availability Status..."
	@curl -s http://localhost:4000/api/v1/data/availability | jq '.data.summary'

# View backfill job history
backfill-status:
	@echo "ğŸ“‹ Backfill Jobs..."
	@curl -s http://localhost:4000/api/v1/backfill | jq '.data.jobs[:5]'


test:
	cd layer-1-ingestion && npm test
	cd layer-2-processing && npm test

test-layer1:
	cd layer-1-ingestion && npm test

# ===========================================================
# 6. LOCAL DEVELOPMENT
# ===========================================================
# All layer targets load root .env for DATABASE_URL, REDIS_URL, KAFKA_BROKERS, etc.

dev: infra
	@echo "âœ… Dev environment ready. Run layers manually."

layer1:
	@echo "ğŸš€ Starting Layer 1 (Ingestion)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-1-ingestion && npm run dev

layer2:
	@echo "ğŸš€ Starting Layer 2 (Processing)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-2-processing && npm run dev

layer4:
	@echo "ğŸš€ Starting Layer 4 (Analysis)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-4-analysis && go run cmd/main.go

layer5:
	@echo "ğŸš€ Starting Layer 5 (Aggregation)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-5-aggregation && go run cmd/main.go

layer6:
	@echo "ğŸš€ Starting Layer 6 (Signal)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-6-signal && npm run dev

layer7-api:
	@echo "ğŸš€ Starting Layer 7 API (Presentation)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-7-presentation-notification/api && npm run dev

layer7-dashboard:
	@echo "ğŸš€ Starting Layer 7 Dashboard..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-7-presentation-notification/stock-analysis-portal && npm run dev

layer-1-ingestion:
	@echo "ğŸš€ Starting Layer 1 (Ingestion)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-1-ingestion && npm run dev

layer-7-backend-api:
	@echo "ğŸš€ Starting Backend API (Layer 7 Core Interface)..."
	@export $$(cat .env | grep -v '^#' | xargs) && cd layer-7-core-interface/api && npm run dev

# ===========================================================
# 7. OBSERVABILITY & LOGS
# ===========================================================

logs:
	$(DC) logs -f

logs-%:
	$(DC) logs -f $*

# ===========================================================
# 8. MAINTENANCE & CLEANUP
# ===========================================================

clean:
	@echo "ğŸ§¹ Cleaning..."
	rm -rf layer-*/node_modules layer-*/dist
	@echo "âœ… Done."

clean-data:
	@echo "âš ï¸  Data is stored in data/ directory"
	@echo "   To delete data, you must manually remove files in that directory."
	@echo "   Action aborted for safety."

prune:
	@echo "âš ï¸  This will delete ALL stopped containers, unused images, and build cache!"
	@read -p "Are you sure? [y/N] " c && [ "$$c" = "y" ] || exit 1
	@echo "ğŸ§¹ Pruning Docker System..."
	@docker system prune -a --volumes -f
	@echo "âœ… Docker Cleaned."

fix-dashboards:
	@echo "ğŸ¨ Fixing Grafana dashboards..."
	@python3 scripts/fix-dashboards-final.py
	@docker restart grafana
	@echo "âœ… Dashboards fixed and Grafana restarted"
	@echo "ï¿½ Refresh your browser to see changes"

fix-kafka:
	@echo "ğŸ”§ Fixing Kafka Cluster ID (Full Reset)..."
	@$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml stop kafka zookeeper kafka-ui
	@echo "ğŸ—‘ï¸ Removing containers..."
	@docker rm -f kafka zookeeper kafka-ui || true
	@echo "ğŸ—‘ï¸ Wiping Kafka data..."
	@rm -rf data/kafka/* || true
	@echo "ğŸ—‘ï¸ Wiping Zookeeper data..."
	@rm -rf data/zookeeper/* || true
	@echo "ğŸš€ Restarting Kafka Stack..."
	@$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml up -d zookeeper kafka kafka-ui
	@echo "âœ… Kafka Stack Reset."
	@echo "â³ Wait 30s, then check http://localhost:8090"
	@$(DC) -f $(COMPOSE_DIR)/docker-compose.infra.yml start kafka
	@echo "ğŸš€ Kafka restarted. Check logs with 'make logs'"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# restart-ingestion: Rebuild and restart ingestion with latest .env
# Use this after changing .env variables like SWARM_CONCURRENCY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
restart-ingestion:
	@echo "ğŸ”„ Rebuilding and restarting ingestion..."
	@$(DC) --env-file .env -f $(COMPOSE_DIR)/docker-compose.app.yml up -d --build ingestion
	@echo "âœ… Ingestion restarted with latest .env values"
	@sleep 3
	@docker logs ingestion --tail 10

# ===========================================================
# 9. SHARING (GATEWAY)
# ===========================================================

share: up gateway
	@echo "ğŸŒ Public tunnel starting..."
	@sleep 5
	@make share-url

share-url:
	@docker logs trading-tunnel 2>&1 | grep -o 'https://.*trycloudflare.com' || echo "â³ Tunnel starting... try again in a few seconds"

share-down:
	@echo "ğŸ›‘ Stopping gateway and tunnel..."
	-$(DC) -f $(COMPOSE_DIR)/docker-compose.gateway.yml down
	@echo "âœ… Stopped."

# ===========================================================
# 10. AWS & PRODUCTION
# ===========================================================

up-aws:
	@echo "â˜ï¸  Starting with AWS Managed Services..."
	@if [ ! -f .env.aws ]; then echo "âŒ .env.aws not found! Copy from .env.aws.example"; exit 1; fi
	docker-compose --env-file .env.aws -f docker-compose.aws.yml up -d --build
	@echo "âœ… App running with AWS infrastructure!"

down-aws:
	@echo "ğŸ›‘ Stopping AWS deployment..."
	docker-compose --env-file .env.aws -f docker-compose.aws.yml down
	@echo "âœ… Stopped."

up-prod:
	@echo "ğŸš€ Starting Production Stack..."
	docker-compose -f docker-compose.prod.yml up -d --build
	@echo "âœ… Production running!"

# ===========================================================
# 11. LEGACY ALIASES
# ===========================================================

docker-up: up
docker-down: down
dashboard: ui
infra-all: infra observe
infra-down: down
