# ==============================================================================
# ðŸ’° COMPLETE PRODUCTION DEPLOYMENT (t3.micro friendly)
# ==============================================================================
# A SINGLE, SELF-CONTAINED file for AWS deployment.
# Includes: Infrastructure, Application, Dashboard, Notifications, Gateway
#
# Usage:
#   sudo docker compose -f docker-compose.prod.yml up -d --build
#
# Memory Budget (~1GB total for t3.micro with 2GB swap):
#   - Infrastructure: ~450MB (Kafka 256M, Zookeeper 128M, Redis 64M)
#   - Application:    ~750MB (L1-L6 + API + Dashboard)
#   - Notifications:  ~100MB (Telegram + Email)
# ==============================================================================

services:

  # ============================================================================
  # INFRASTRUCTURE
  # ============================================================================

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_HEAP_OPTS: "-Xmx128M -Xms128M"
    ports:
      - "2181:2181"
    healthcheck:
      test: [ "CMD-SHELL", "echo stat | nc localhost 2181" ]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 128M
    restart: always

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms256M"
    healthcheck:
      test: [ "CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list" ]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 400M
    restart: always

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 64mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 100M
    restart: always

  timescaledb:
    image: timescale/timescaledb:latest-pg15
    container_name: timescaledb
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-trading}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-trading123}
      POSTGRES_DB: ${POSTGRES_DB:-nifty50}
    command: postgres -c shared_buffers=64MB -c max_connections=50
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U trading" ]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
    restart: always

  # Admin UIs (Optional - can be removed to save memory)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    depends_on:
      - kafka
    restart: always
    profiles:
      - admin

  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redis-commander
    environment:
      REDIS_HOSTS: local:redis:6379
    ports:
      - "8085:8081"
    depends_on:
      - redis
    restart: always
    profiles:
      - admin

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@admin.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin123}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    depends_on:
      - timescaledb
    restart: always
    profiles:
      - admin

  # ============================================================================
  # APPLICATION LAYERS (L1-L6)
  # ============================================================================

  # Layer 1: Ingestion
  ingestion:
    build:
      context: ./layer-1-ingestion
    container_name: ingestion
    environment:
      - KAFKA_BROKERS=kafka:29092
      - REDIS_URL=redis://redis:6379
      - MARKET_DATA_PROVIDER=${MARKET_DATA_PROVIDER:-mstock}
      - ZERODHA_API_KEY=${ZERODHA_API_KEY}
      - ZERODHA_ACCESS_TOKEN=${ZERODHA_ACCESS_TOKEN}
      - MSTOCK_API_KEY=${MSTOCK_API_KEY}
      - MSTOCK_ACCESS_TOKEN=${MSTOCK_ACCESS_TOKEN}
      - MSTOCK_CLIENT_CODE=${MSTOCK_CLIENT_CODE}
      - MSTOCK_PASSWORD=${MSTOCK_PASSWORD}
      - MSTOCK_TOTP_SECRET=${MSTOCK_TOTP_SECRET}
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 150M
    restart: always

  # Layer 2: Processing
  processing:
    build:
      context: ./layer-2-processing
    container_name: processing
    environment:
      - KAFKA_BROKERS=kafka:29092
      - REDIS_URL=redis://redis:6379
      - TIMESCALE_URL=postgresql://trading:trading123@timescaledb:5432/nifty50
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3002/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 150M
    restart: always

  # Layer 4: Analysis (Go)
  analysis:
    build:
      context: ./layer-4-analysis
    container_name: analysis
    environment:
      - REDIS_URL=redis://redis:6379
      - KAFKA_BROKERS=kafka:29092
      - TIMESCALE_URL=postgresql://trading:trading123@timescaledb:5432/nifty50
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8081/metrics" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 150M
    restart: always

  # Layer 5: Aggregation (Go)
  aggregation:
    build:
      context: ./layer-5-aggregation
    container_name: aggregation
    environment:
      - REDIS_URL=redis://redis:6379
      - TIMESCALE_URL=postgresql://trading:trading123@timescaledb:5432/nifty50
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 120M
    restart: always

  # Layer 6: Signal Generation
  signal:
    build:
      context: ./layer-6-signal
    container_name: signal
    environment:
      - REDIS_URL=redis://redis:6379
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8082/metrics" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 120M
    restart: always

  # ============================================================================
  # LAYER 7: PRESENTATION & NOTIFICATION
  # ============================================================================

  # API Server
  backend-api:
    build:
      context: ./layer-7-presentation-notification/api
    container_name: backend-api
    ports:
      - "4000:4000"
    environment:
      - REDIS_URL=redis://redis:6379
      - TIMESCALE_URL=postgresql://trading:trading123@timescaledb:5432/nifty50
    depends_on:
      redis:
        condition: service_healthy
      timescaledb:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 150M
    restart: always

  # Dashboard (Next.js)
  dashboard:
    build:
      context: ./layer-7-presentation-notification/stock-analysis-portal
    container_name: dashboard
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=/api/v1
      - NEXT_PUBLIC_WS_URL=/
      - NEXT_PUBLIC_APP_VERSION=${APP_VERSION}
    depends_on:
      backend-api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/" ]
      interval: 60s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 250M
    restart: always

  # Telegram Bot (Guru Ji)
  telegram-bot:
    build:
      context: ./layer-7-presentation-notification/telegram-bot
    container_name: telegram-bot
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - REDIS_URL=redis://redis:6379
      - API_URL=http://backend-api:4000
    depends_on:
      redis:
        condition: service_healthy
      backend-api:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:7000/metrics" ]
      interval: 60s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 80M
    restart: always

  # Email Service
  email-service:
    build:
      context: ./layer-7-presentation-notification/email-service
    container_name: email-service
    environment:
      - REDIS_URL=redis://redis:6379
      - SMTP_HOST=${SMTP_HOST:-}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_USER=${SMTP_USER:-}
      - SMTP_PASS=${SMTP_PASS:-}
      - ADMIN_EMAIL=${ADMIN_EMAIL:-}
    depends_on:
      - redis
    restart: always
    deploy:
      resources:
        limits:
          memory: 50M

  # ============================================================================
  # GATEWAY (Nginx Reverse Proxy)
  # ============================================================================

  gateway:
    image: nginx:alpine
    container_name: trading-gateway
    ports:
      - "80:80"
    volumes:
      - ./infrastructure/gateway/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - dashboard
      - backend-api
    restart: always

  # ============================================================================
  # OBSERVABILITY (Prometheus, Grafana, Loki)
  # ============================================================================

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    restart: always
    deploy:
      resources:
        limits:
          memory: 150M

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin123}
      GF_USERS_ALLOW_SIGN_UP: 'false'
      GF_SERVER_DOMAIN: 'localhost'
      GF_SERVER_ROOT_URL: 'http://localhost:3001/'
      GF_SECURITY_ALLOW_EMBEDDING: 'true'
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./infrastructure/monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      - prometheus
    restart: always
    deploy:
      resources:
        limits:
          memory: 150M

  loki:
    image: grafana/loki:latest
    container_name: loki
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    restart: always
    deploy:
      resources:
        limits:
          memory: 100M

  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./infrastructure/monitoring/promtail-config.yaml:/etc/promtail/config.yaml
    command: -config.file=/etc/promtail/config.yaml
    restart: always
    deploy:
      resources:
        limits:
          memory: 50M

  # Exporters
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    environment:
      REDIS_ADDR: redis://redis:6379
    ports:
      - "9121:9121"
    depends_on:
      - redis
    deploy:
      resources:
        limits:
          memory: 32M
    restart: always

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    environment:
      DATA_SOURCE_NAME: 'postgresql://trading:trading123@timescaledb:5432/nifty50?sslmode=disable'
    ports:
      - "9187:9187"
    depends_on:
      - timescaledb
    deploy:
      resources:
        limits:
          memory: 32M
    restart: always

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    privileged: true
    ports:
      - "8083:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    deploy:
      resources:
        limits:
          memory: 64M
    restart: always

  otel-collector:
    image: otel/opentelemetry-collector:latest
    container_name: otel-collector
    command: [ '--config=/etc/otel-collector-config.yaml' ]
    volumes:
      - ./infrastructure/monitoring/otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"
      - "4318:4318"
    deploy:
      resources:
        limits:
          memory: 64M
    restart: always
    profiles:
      - full

  # ============================================================================
  # PUBLIC TUNNEL (Cloudflare - Optional)
  # ============================================================================

  tunnel:
    image: cloudflare/cloudflared:latest
    container_name: trading-tunnel
    command: tunnel --url http://gateway:80
    depends_on:
      - gateway
    restart: always
    deploy:
      resources:
        limits:
          memory: 64M
    profiles:
      - tunnel

# ============================================================================
# VOLUMES
# ============================================================================
volumes:
  timescaledb_data:
  prometheus_data:
  grafana_data:
