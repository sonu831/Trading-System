{
  "annotations": {
    "list": []
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 0,
  "id": null,
  "links": [],
  "liveNow": false,
  "panels": [
    {
      "gridPos": {
        "h": 3,
        "w": 24,
        "x": 0,
        "y": 0
      },
      "id": 1,
      "options": {
        "content": "# \ud83e\udde0 AI Stack Analytics\n### Real-time observability for Ollama & AI Inference Engine",
        "mode": "markdown"
      },
      "title": "",
      "type": "text"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 0,
        "y": 3
      },
      "id": 2,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(rate(ai_token_usage_total{type='output'}[1m]))",
          "legendFormat": "Output Rate"
        }
      ],
      "title": "Output Token Rate",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 6,
        "y": 3
      },
      "id": 3,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "mean"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(ai_request_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "p95 Latency"
        }
      ],
      "title": "Inference Latency (p95)",
      "type": "stat",
      "fieldConfig": {
        "defaults": {
          "unit": "s",
          "color": {
            "mode": "thresholds"
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "orange",
                "value": 10
              },
              {
                "color": "red",
                "value": 30
              }
            ]
          }
        }
      }
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 12,
        "y": 3
      },
      "id": 4,
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(increase(ai_token_usage_total[24h]))",
          "legendFormat": "Tokens (24h)"
        }
      ],
      "title": "Total Tokens Today",
      "type": "stat"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 4,
        "w": 6,
        "x": 18,
        "y": 3
      },
      "id": 5,
      "options": {
        "colorMode": "value",
        "graphMode": "none",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "sum(rate(promhttp_metric_handler_requests_total{job='ai-inference',code=~'5..'}[5m]))",
          "legendFormat": "Errors"
        }
      ],
      "title": "AI Error Rate",
      "type": "stat",
      "fieldConfig": {
        "defaults": {
          "thresholds": {
            "steps": [
              {
                "color": "green",
                "value": null
              },
              {
                "color": "red",
                "value": 0.1
              }
            ]
          }
        }
      }
    },
    {
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 7
      },
      "id": 10,
      "title": "Token Usage & Models",
      "type": "row",
      "collapsed": false,
      "panels": []
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 8,
        "w": 16,
        "x": 0,
        "y": 8
      },
      "id": 11,
      "options": {
        "legend": {
          "displayMode": "table",
          "placement": "right"
        }
      },
      "targets": [
        {
          "expr": "rate(ai_token_usage_total{type='input'}[1m])",
          "legendFormat": "{{model}} (Input)"
        },
        {
          "expr": "rate(ai_token_usage_total{type='output'}[1m])",
          "legendFormat": "{{model}} (Output)"
        }
      ],
      "title": "Token Usage Rate (per model)",
      "type": "timeseries"
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 8,
        "w": 8,
        "x": 16,
        "y": 8
      },
      "id": 12,
      "options": {
        "pieType": "donut",
        "reduceOptions": {
          "calcs": [
            "lastNotNull"
          ],
          "fields": "",
          "values": false
        }
      },
      "targets": [
        {
          "expr": "sum by (model) (increase(ai_token_usage_total[1h]))",
          "legendFormat": "{{model}}"
        }
      ],
      "title": "Model Distribution (1h)",
      "type": "piechart"
    },
    {
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 16
      },
      "id": 20,
      "title": "Infrastructure",
      "type": "row",
      "collapsed": false,
      "panels": []
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 0,
        "y": 17
      },
      "id": 21,
      "title": "AI & Ollama CPU",
      "type": "timeseries",
      "targets": [
        {
          "expr": "rate(container_cpu_usage_seconds_total{container=~\"ai-inference|ollama\", cpu=\"total\"}[1m])",
          "legendFormat": "{{container}}"
        }
      ]
    },
    {
      "datasource": {
        "type": "prometheus",
        "uid": "prometheus-datasource"
      },
      "gridPos": {
        "h": 8,
        "w": 12,
        "x": 12,
        "y": 17
      },
      "id": 22,
      "title": "AI & Ollama Memory",
      "type": "timeseries",
      "targets": [
        {
          "expr": "container_memory_usage_bytes{container=~\"ai-inference|ollama\"}",
          "legendFormat": "{{container}}"
        }
      ],
      "fieldConfig": {
        "defaults": {
          "unit": "bytes"
        }
      }
    },
    {
      "gridPos": {
        "h": 1,
        "w": 24,
        "x": 0,
        "y": 25
      },
      "id": 30,
      "title": "Detailed Logs",
      "type": "row",
      "collapsed": false,
      "panels": []
    },
    {
      "datasource": {
        "type": "loki",
        "uid": "loki-datasource"
      },
      "gridPos": {
        "h": 10,
        "w": 24,
        "x": 0,
        "y": 26
      },
      "id": 31,
      "options": {
        "showTime": true,
        "wrapLogMessage": true,
        "sortOrder": "Descending"
      },
      "targets": [
        {
          "expr": "{container=~\"ai-inference|ollama|analysis\"}"
        }
      ],
      "title": "AI Stack & Analysis Logs",
      "type": "logs"
    }
  ],
  "refresh": "5s",
  "schemaVersion": 38,
  "style": "dark",
  "tags": [
    "ai",
    "ollama",
    "analytics"
  ],
  "templating": {
    "list": []
  },
  "time": {
    "from": "now-1h",
    "to": "now"
  },
  "timezone": "browser",
  "title": "AI Stack Analytics",
  "uid": "ai-analytics",
  "version": 1
}